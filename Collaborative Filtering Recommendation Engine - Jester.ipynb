{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7ae065",
   "metadata": {},
   "source": [
    "# Jester Collaborative Filtering Recommendation Engine\n",
    "\n",
    "Prepared by: Darwin\n",
    "\n",
    "Instructor: Forward School\n",
    "\n",
    "##### Abstract\n",
    "This assignment is to performing a collaborative filtering on the Jester Dataset with the dimensions of ***7699 by 159 matrix*** and building a recommendation engine for recommending the next *jokes*\n",
    "\n",
    "(http://eigentaste.berkeley.edu/dataset/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d525a7",
   "metadata": {},
   "source": [
    "## Part 1: Data Understanding\n",
    "**Over 100,000 new ratings from 7,699 total users: data collected from April 2015 - Nov 2019** </br>\n",
    "The text of the jokes: Dataset4JokeSet.xlsx (31 KB)\n",
    "\n",
    "Format:\n",
    "1. An excel sheet with 158 rows.\n",
    "2. The row number corresponds to the joke ID referred to in the Excel files below\n",
    "\n",
    "The Ratings Data: Jester_Rating.xlsx (3 MB)\n",
    "\n",
    "Format:\n",
    "\n",
    "* The data is formatted as an excel file representing a ***7699 by 159 matrix*** with rows as users and columns as jokes. The left-most column represents the amount of jokes rated by each user. There are a total of 7699 users and 158 jokes in this dataset.\n",
    "* Each rating is from (-10.00 to +10.00) and 99 corresponds to a null rating (user did not rate that joke)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8309f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_excel)\n",
    "\n",
    "import matplotlib.pyplot as plt #visualization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87eb7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surprise library\n",
    "\n",
    "# For building the dataset (sparse matrix) & ratings\n",
    "from surprise import Dataset, Reader\n",
    "\n",
    "# For run cross-validation or split and search the best parameters for a prediction algorithm\n",
    "from surprise.model_selection import train_test_split, GridSearchCV, cross_validate, KFold\n",
    "\n",
    "# Similarities components, To compute similarity metrics between users or items\n",
    "from surprise.similarities import cosine, msd, pearson, pearson_baseline\n",
    "\n",
    "# k-NN inspired algorithms, *Memory-based Collaborative Filtering*\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore\n",
    "\n",
    "# Matrix Factorization-based algorithms, *Model-based Collaborative Filtering*\n",
    "from surprise import SVD, SVDpp\n",
    "\n",
    "# Others Models from Surprise Library, also a *Model-based Collaborative Filtering*\n",
    "from surprise import SlopeOne, CoClustering\n",
    "\n",
    "# to compare result of each models\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349b67d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jokes_1</th>\n",
       "      <td>A man visits the doctor. The doctor says \"I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes_2</th>\n",
       "      <td>This couple had an excellent relationship goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes_3</th>\n",
       "      <td>Q. What's 200 feet long and has 4 teeth?   A. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes_4</th>\n",
       "      <td>Q. What's the difference between a man and a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes_5</th>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address?  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes_154</th>\n",
       "      <td>Poodle: \"My life is a mess. My owner is mean, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes_155</th>\n",
       "      <td>Did you hear that NASA has launched several co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes_156</th>\n",
       "      <td>A bear walks into a bar and says,\"I'd like a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes_157</th>\n",
       "      <td>A dog goes into a bar and orders a martini. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes_158</th>\n",
       "      <td>I'm reading a great book about antigravity -- ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       jokes\n",
       "jokes_1    A man visits the doctor. The doctor says \"I ha...\n",
       "jokes_2    This couple had an excellent relationship goin...\n",
       "jokes_3    Q. What's 200 feet long and has 4 teeth?   A. ...\n",
       "jokes_4    Q. What's the difference between a man and a t...\n",
       "jokes_5    Q.\\tWhat's O. J. Simpson's Internet address?  ...\n",
       "...                                                      ...\n",
       "jokes_154  Poodle: \"My life is a mess. My owner is mean, ...\n",
       "jokes_155  Did you hear that NASA has launched several co...\n",
       "jokes_156  A bear walks into a bar and says,\"I'd like a b...\n",
       "jokes_157  A dog goes into a bar and orders a martini. Th...\n",
       "jokes_158  I'm reading a great book about antigravity -- ...\n",
       "\n",
       "[158 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How do you keep a computer programmer in the  shower all day long?  A: Give them a shampoo with a label that says \"rinse, lather, repeat\".\n"
     ]
    }
   ],
   "source": [
    "# Import jokes text\n",
    "df_jokes = pd.read_excel('Data/Dataset4JokeSet.xlsx', header=None, names = ['jokes'])\n",
    "\n",
    "# Shift the index by 1, and add a prefix for easier representations & visualization\n",
    "df_jokes.set_index('jokes_' + (df_jokes.index + 1).astype(str), inplace = True )\n",
    "\n",
    "display(df_jokes)\n",
    "print(df_jokes['jokes']['jokes_82'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1763785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>5.61</td>\n",
       "      <td>-4.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.93</td>\n",
       "      <td>4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>27.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>26.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>8.63</td>\n",
       "      <td>99.00</td>\n",
       "      <td>6.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.26</td>\n",
       "      <td>99.00</td>\n",
       "      <td>-2.66</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>64.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.03</td>\n",
       "      <td>99.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7699 rows Ã— 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9    ...    149  \\\n",
       "0      1.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  ...  99.00   \n",
       "1      1.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  ...  99.00   \n",
       "2      4.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  ...  99.00   \n",
       "3     47.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  ...  99.00   \n",
       "4     13.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  ...  99.00   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "7694  27.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  ...   0.00   \n",
       "7695   1.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  ...  99.00   \n",
       "7696  26.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  ...  99.00   \n",
       "7697  64.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  ...   2.03   \n",
       "7698   2.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  ...  99.00   \n",
       "\n",
       "        150    151    152    153   154    155    156    157    158  \n",
       "0     99.00  99.00  99.00  99.00  99.0  99.00  99.00  99.00  99.00  \n",
       "1     99.00  99.00  99.00  99.00  99.0  99.00  99.00  99.00  99.00  \n",
       "2     99.00  99.00  99.00  99.00  99.0  99.00  99.00  99.00  99.00  \n",
       "3     99.00   5.61  -4.51   0.00   0.0  99.00   0.00   5.93   4.19  \n",
       "4     99.00  99.00  99.00  99.00   0.0  99.00  99.00  99.00   0.00  \n",
       "...     ...    ...    ...    ...   ...    ...    ...    ...    ...  \n",
       "7694  99.00   0.00   0.00   0.00  99.0   0.00   0.00   0.00  99.00  \n",
       "7695  99.00  99.00  99.00  99.00  99.0  99.00  99.00  99.00  99.00  \n",
       "7696   8.63  99.00   6.76   0.00   3.5   6.26  99.00  -2.66   0.65  \n",
       "7697  99.00   2.05   2.05   0.73   0.0   2.97   0.57   0.00   0.00  \n",
       "7698  99.00  99.00  99.00  99.00  99.0  99.00  99.00  99.00  99.00  \n",
       "\n",
       "[7699 rows x 159 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## import 7699 by 159 matrix ratings\n",
    "df_ratings = pd.read_excel('Data/Jester_Rating.xlsx', header=None)\n",
    "display(df_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f490eb",
   "metadata": {},
   "source": [
    "### 1.1: Describe Data\n",
    "\n",
    "* There are 158 columns (represent each 158 jokes) inside the dataset, and all of the datatype are **float**.\n",
    "* Each rating is from (-10.00 to +10.00)\n",
    "* 99 corresponds to a null rating (user did not rate that joke)\n",
    "* Since Recommendation Engine is a unsupervised learning, there are no Y variables here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c9ffa",
   "metadata": {},
   "source": [
    "## Part 2: Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03b01f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jokes without any ratings :  Index(['jokes_1', 'jokes_2', 'jokes_3', 'jokes_4', 'jokes_5', 'jokes_6',\n",
      "       'jokes_9', 'jokes_10', 'jokes_11', 'jokes_12', 'jokes_14', 'jokes_20',\n",
      "       'jokes_27', 'jokes_31', 'jokes_43', 'jokes_51', 'jokes_52', 'jokes_61',\n",
      "       'jokes_73', 'jokes_80', 'jokes_100', 'jokes_116'],\n",
      "      dtype='object')\n",
      "Memory Size before datatype conversion & manipulation: 9.34 MB\n",
      "Memory Size after  datatype conversion & manipulation: 3.99 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jokes_7</th>\n",
       "      <th>jokes_8</th>\n",
       "      <th>jokes_13</th>\n",
       "      <th>jokes_15</th>\n",
       "      <th>jokes_16</th>\n",
       "      <th>jokes_17</th>\n",
       "      <th>jokes_18</th>\n",
       "      <th>jokes_19</th>\n",
       "      <th>jokes_21</th>\n",
       "      <th>jokes_22</th>\n",
       "      <th>...</th>\n",
       "      <th>jokes_149</th>\n",
       "      <th>jokes_150</th>\n",
       "      <th>jokes_151</th>\n",
       "      <th>jokes_152</th>\n",
       "      <th>jokes_153</th>\n",
       "      <th>jokes_154</th>\n",
       "      <th>jokes_155</th>\n",
       "      <th>jokes_156</th>\n",
       "      <th>jokes_157</th>\n",
       "      <th>jokes_158</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.41</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.61</td>\n",
       "      <td>-4.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.93</td>\n",
       "      <td>4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.66</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.52</td>\n",
       "      <td>5.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7699 rows Ã— 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      jokes_7  jokes_8  jokes_13  jokes_15  jokes_16  jokes_17  jokes_18  \\\n",
       "0         NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1         NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2         NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3         NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4         NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...       ...      ...       ...       ...       ...       ...       ...   \n",
       "7694      NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "7695      NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "7696      NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "7697      NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "7698      NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "      jokes_19  jokes_21  jokes_22  ...  jokes_149  jokes_150  jokes_151  \\\n",
       "0          NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "1          NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "2        -5.98       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "3        -5.41     -4.59       NaN  ...        NaN        NaN       5.61   \n",
       "4        -7.72       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "7694      0.00      0.00       NaN  ...       0.00        NaN       0.00   \n",
       "7695     -9.51       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "7696     -7.93       NaN       NaN  ...        NaN       8.63        NaN   \n",
       "7697      2.52      5.37       NaN  ...       2.03        NaN       2.05   \n",
       "7698      4.59       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "\n",
       "      jokes_152  jokes_153  jokes_154  jokes_155  jokes_156  jokes_157  \\\n",
       "0           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3         -4.51       0.00        0.0        NaN       0.00       5.93   \n",
       "4           NaN        NaN        0.0        NaN        NaN        NaN   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "7694       0.00       0.00        NaN       0.00       0.00       0.00   \n",
       "7695        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "7696       6.76       0.00        3.5       6.26        NaN      -2.66   \n",
       "7697       2.05       0.73        0.0       2.97       0.57       0.00   \n",
       "7698        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "      jokes_158  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3          4.19  \n",
       "4          0.00  \n",
       "...         ...  \n",
       "7694        NaN  \n",
       "7695        NaN  \n",
       "7696       0.65  \n",
       "7697       0.00  \n",
       "7698        NaN  \n",
       "\n",
       "[7699 rows x 136 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Original memory usage\n",
    "before  = df_ratings.memory_usage().sum() / 1024 / 1024\n",
    "\n",
    "# removing 1st columns since it only represents the amount of jokes rated by each user\n",
    "df_ratings.drop(0, axis = 1, inplace = True)\n",
    "\n",
    "# rename columns so that it was similar to df_jokes\n",
    "df_ratings = df_ratings.add_prefix('jokes_')\n",
    "\n",
    "#Replacing 99 with actual numpy null values\n",
    "df_ratings.replace(99.0, np.nan, inplace = True)\n",
    "\n",
    "# drop entire column if the entire column is null (no ratings from any users)\n",
    "null_ratings = df_ratings.columns[df_ratings.isnull().all()]\n",
    "df_ratings.dropna(how='all', axis=1, inplace = True)\n",
    "\n",
    "# convert dtypes to float32 for faster processing\n",
    "df_ratings = df_ratings.astype(np.float32) \n",
    "after = df_ratings.memory_usage().sum() / 1024 / 1024\n",
    "print (\"\\n Memory Size before datatype conversion & manipulation: %.2f MB\" %(before))\n",
    "print (\"\\n Memory Size after  datatype conversion & manipulation: %.2f MB\" %(after))\n",
    "\n",
    "print (\"\\n\\n\\n Jokes without any ratings : \" ,null_ratings)\n",
    "display(df_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb51c52",
   "metadata": {},
   "source": [
    "> 22 of the jokes don't have ratings, their ids are: {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 14, 20, 27, 31, 43, 51, 52, 61, 73, 80, 100, 116}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cb54ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>jokesId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jokes_72</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>jokes_72</td>\n",
       "      <td>8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>jokes_19</td>\n",
       "      <td>-5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>jokes_35</td>\n",
       "      <td>-4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>jokes_72</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106484</th>\n",
       "      <td>7697</td>\n",
       "      <td>jokes_156</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106485</th>\n",
       "      <td>7697</td>\n",
       "      <td>jokes_157</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106486</th>\n",
       "      <td>7697</td>\n",
       "      <td>jokes_158</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106487</th>\n",
       "      <td>7698</td>\n",
       "      <td>jokes_19</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106488</th>\n",
       "      <td>7698</td>\n",
       "      <td>jokes_72</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106489 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId    jokesId  rating\n",
       "0            0   jokes_72    3.70\n",
       "1            1   jokes_72    8.21\n",
       "2            2   jokes_19   -5.98\n",
       "3            2   jokes_35   -4.47\n",
       "4            2   jokes_72    1.59\n",
       "...        ...        ...     ...\n",
       "106484    7697  jokes_156    0.57\n",
       "106485    7697  jokes_157    0.00\n",
       "106486    7697  jokes_158    0.00\n",
       "106487    7698   jokes_19    4.59\n",
       "106488    7698   jokes_72    3.86\n",
       "\n",
       "[106489 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stack = df_ratings.stack().reset_index()\n",
    "df_stack.columns = ['userId', 'jokesId', 'rating']\n",
    "df_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6832af7c",
   "metadata": {},
   "source": [
    "# Part 3: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d4f19",
   "metadata": {},
   "source": [
    "Within the group of collaborative filtering, the two most well-known distinct approaches are:\n",
    "\n",
    "* `Memory-based models`, which calculate the similarities between users / items based on user-item rating pairs.\n",
    "    > Example : `K-Neareast Neighbors` of the **item-item** ratings matrix\n",
    "\n",
    "* `Model-based models`, which use some sort of machine learning algorithm to estimate the ratings. \n",
    "    > Example : `Singular Value Decomposition` of the **user-item** ratings matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0df6328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users  :  7407 \n",
      "\n",
      "Number of items  :  136 \n",
      "\n",
      "Number of ratings:  85191 \n",
      "\n",
      "Rating Scale:  (-10.0, 10.0) \n",
      "\n",
      "Global Mean :  0.5022379127729938 \n",
      "\n",
      "Length of Testset :  21298 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a Suprise Reader with rating_scale as a tuple of lowest and highest possible range\n",
    "reader = Reader(rating_scale = (-10.0, 10.0))\n",
    "\n",
    "# Convert data into a sparse matrix where individual ratings are elements in this matrix\n",
    "data = Dataset.load_from_df(df_stack[['userId', 'jokesId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c560feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users  :  7407 \n",
      "\n",
      "Number of items  :  136 \n",
      "\n",
      "Number of ratings:  85191 \n",
      "\n",
      "Rating Scale:  (-10.0, 10.0) \n",
      "\n",
      "Global Mean :  0.5022379127729938 \n",
      "\n",
      "\n",
      "Length of Testset :  21298 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example of inner id  :  [0, 1, 2, 3, 4] \n",
      "\n",
      "Example of raw id    :  ['jokes_72', 'jokes_117', 'jokes_107', 'jokes_19', 'jokes_77'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into trainset and testset, test_size is set to 20%:\n",
    "trainset, testset = train_test_split(data, test_size=0.20, random_state = 42)\n",
    "\n",
    "print('Number of users  : ', trainset.n_users, '\\n')\n",
    "print('Number of items  : ', trainset.n_items, '\\n')\n",
    "print('Number of ratings: ', trainset.n_ratings, '\\n')\n",
    "print('Rating Scale: ', trainset.rating_scale, '\\n')\n",
    "print('Global Mean : ', trainset.global_mean, '\\n\\n')\n",
    "print('Length of Testset : ', len(testset), '\\n\\n\\n\\n')\n",
    "\n",
    "# Convert an item inner id to a raw id, \n",
    "trainset_iids = list(trainset.all_items())\n",
    "iid_converter = lambda x: trainset.to_raw_iid(x)\n",
    "trainset_raw_iids = list(map(iid_converter, trainset_iids))\n",
    "\n",
    "print('Example of inner id  : ', trainset_iids[:5], '\\n')\n",
    "print('Example of raw id    : ', trainset_raw_iids[:5], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba6857",
   "metadata": {},
   "source": [
    "In layman terms, On trainset creation, each raw id is mapped to a unique integer called inner id\n",
    "* Raw iid is the actual index named in the original file\n",
    "* Inner iid is the index created during trainset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d00257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  7699 \n",
      "\n",
      "Number of items:  136 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we are using the trainsetfull to save distance metrics\n",
    "trainsetfull = data.build_full_trainset()\n",
    "print('Number of users: ', trainsetfull.n_users, '\\n')\n",
    "print('Number of items: ', trainsetfull.n_items, '\\n')\n",
    "\n",
    "trainsetfull_iids = list(trainsetfull.all_items())\n",
    "iid_converter = lambda x: trainsetfull.to_raw_iid(x)\n",
    "trainsetfull_raw_iids = list(map(iid_converter, trainsetfull_iids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b8456",
   "metadata": {},
   "source": [
    "# Part 4: Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ce7d8e",
   "metadata": {},
   "source": [
    "## 4.1: Memory-based models Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261ca01",
   "metadata": {},
   "source": [
    "### 4.1.1: `k-NN inspired algorithms` - kNN Models without Baseline\n",
    "\n",
    "First, we define the similarity options, to be used by different models. The four options are:\n",
    "- `msd`\n",
    "- `cosine`\n",
    "- `pearson`\n",
    "- `pearson_baseline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c7914f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_msd = {'name':'MSD', 'user_based':False}\n",
    "sim_cos = {'name':'cosine', 'user_based':False}\n",
    "sim_pearson = {'name':'pearson', 'user_based':False}\n",
    "sim_pearson_baseline = {'name': 'pearson_baseline','user_based':False, 'shrinkage': 100}\n",
    "\n",
    "sim_options = [sim_msd, sim_cos, sim_pearson, sim_pearson_baseline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d6e4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neighbors\n",
    "list_of_ks = [10,20,40]\n",
    "\n",
    "# empty list to store kNN scores\n",
    "kNN_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07145a8",
   "metadata": {},
   "source": [
    "On to the modelling. \n",
    "\n",
    "`KNNBasic`, `KNNWithMean`, `KNNWithZScore` can be used with first three sims, to tune: `k`, number of neighbors, looking at these first. \n",
    "\n",
    "Starting with the three `kNN` models that have no baseline attached to them. We are using `cross_validate` on all of them, and then save the results\n",
    "\n",
    "Then, we pick the best performing model, and train it on the trainset only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60327814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently calculating sim_option = MSD and k = 10 ...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = MSD and k = 20 ...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = MSD and k = 40 ...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = cosine and k = 10 ...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = cosine and k = 20 ...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = cosine and k = 40 ...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = pearson and k = 10 ...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = pearson and k = 20 ...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = pearson and k = 40 ...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# KNNBasic\n",
    "for curr_sim_option in sim_options[0:3]:\n",
    "\n",
    "    for curr_k in list_of_ks:\n",
    "        \n",
    "        print(\n",
    "            'Currently calculating sim_option = ' + str(curr_sim_option['name']) + \\\n",
    "            ' and k = ' + str(curr_k) + ' ...' )        \n",
    "        algo = KNNBasic(k = curr_k, sim_options = curr_sim_option)\n",
    "        results = cross_validate(algo, data, measures=['RMSE'], cv=3, return_train_measures=True);\n",
    "        \n",
    "        kNN_scores.append(['KNNBasic', curr_sim_option['name'], str(curr_k), \n",
    "                        str(np.mean(results['train_rmse'])), str(np.mean(results['test_rmse']))]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d41934cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently calculating sim_option = MSD and k = 10 ...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = MSD and k = 20 ...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = MSD and k = 40 ...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = cosine and k = 10 ...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = cosine and k = 20 ...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = cosine and k = 40 ...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = pearson and k = 10 ...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = pearson and k = 20 ...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = pearson and k = 40 ...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# KNNWithMeans\n",
    "for curr_sim_option in sim_options[0:3]:\n",
    "\n",
    "    for curr_k in list_of_ks:\n",
    "        \n",
    "        print(\n",
    "            'Currently calculating sim_option = ' + str(curr_sim_option['name']) + \\\n",
    "            ' and k = ' + str(curr_k) + ' ...' )\n",
    "        algo = KNNWithMeans(k = curr_k, sim_options = curr_sim_option)\n",
    "        results = cross_validate(algo, data, measures=['RMSE'], cv=3, return_train_measures=True);\n",
    "        \n",
    "        kNN_scores.append(['KNNWithMeans', curr_sim_option['name'], str(curr_k), \n",
    "                        str(np.mean(results['train_rmse'])), str(np.mean(results['test_rmse']))]\n",
    "                      )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5dd244ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently calculating sim_option = MSD and k = 10 ...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = MSD and k = 20 ...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = MSD and k = 40 ...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = cosine and k = 10 ...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = cosine and k = 20 ...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = cosine and k = 40 ...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = pearson and k = 10 ...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = pearson and k = 20 ...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Currently calculating sim_option = pearson and k = 40 ...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# KNNWithZScore\n",
    "for curr_sim_option in sim_options[0:3]:\n",
    "\n",
    "    for curr_k in list_of_ks:\n",
    "        \n",
    "        print(\n",
    "            'Currently calculating sim_option = ' + str(curr_sim_option['name']) + \\\n",
    "            ' and k = ' + str(curr_k) + ' ...' )\n",
    "        algo = KNNWithZScore(k = curr_k, sim_options = curr_sim_option)\n",
    "        results = cross_validate(algo, data, measures=['RMSE'], cv=3, return_train_measures=True);\n",
    "\n",
    "        kNN_scores.append(['KNNWithZScore', curr_sim_option['name'], str(curr_k), \n",
    "                        str(np.mean(results['train_rmse'])), str(np.mean(results['test_rmse']))]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abb65b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>similarity_option</th>\n",
       "      <th>k</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>pearson</td>\n",
       "      <td>40</td>\n",
       "      <td>3.2531799491999114</td>\n",
       "      <td>4.573265990871269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>3.159682964715261</td>\n",
       "      <td>4.5799248468706075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>cosine</td>\n",
       "      <td>40</td>\n",
       "      <td>3.2903850378669244</td>\n",
       "      <td>4.583245241152444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>pearson</td>\n",
       "      <td>20</td>\n",
       "      <td>3.1003618713234586</td>\n",
       "      <td>4.5905238569670885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>MSD</td>\n",
       "      <td>20</td>\n",
       "      <td>1.3359292867425185</td>\n",
       "      <td>4.5925886023067655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>MSD</td>\n",
       "      <td>40</td>\n",
       "      <td>1.6799542931536193</td>\n",
       "      <td>4.595086217615626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KNNWithZScore</td>\n",
       "      <td>cosine</td>\n",
       "      <td>40</td>\n",
       "      <td>3.296224688519716</td>\n",
       "      <td>4.5953194284848875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNNWithZScore</td>\n",
       "      <td>MSD</td>\n",
       "      <td>40</td>\n",
       "      <td>1.6825021258480246</td>\n",
       "      <td>4.5994594505434705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNNWithZScore</td>\n",
       "      <td>pearson</td>\n",
       "      <td>40</td>\n",
       "      <td>3.2576625023139862</td>\n",
       "      <td>4.600459390823622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KNNWithZScore</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>3.1618570717831602</td>\n",
       "      <td>4.601089923272977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>3.1617757985124015</td>\n",
       "      <td>4.604718491496385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KNNWithZScore</td>\n",
       "      <td>MSD</td>\n",
       "      <td>20</td>\n",
       "      <td>1.3396796792224153</td>\n",
       "      <td>4.60527867262265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>cosine</td>\n",
       "      <td>40</td>\n",
       "      <td>3.3030329571595445</td>\n",
       "      <td>4.6057789357366845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNNWithZScore</td>\n",
       "      <td>pearson</td>\n",
       "      <td>20</td>\n",
       "      <td>3.106248847622633</td>\n",
       "      <td>4.6070554199151355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>MSD</td>\n",
       "      <td>40</td>\n",
       "      <td>1.6936313947962665</td>\n",
       "      <td>4.616938317859895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>MSD</td>\n",
       "      <td>20</td>\n",
       "      <td>1.3413152744327146</td>\n",
       "      <td>4.618288844621761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>MSD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.972312697133904</td>\n",
       "      <td>4.618542054046472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>cosine</td>\n",
       "      <td>10</td>\n",
       "      <td>2.9176009729694705</td>\n",
       "      <td>4.62400255806853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>pearson</td>\n",
       "      <td>10</td>\n",
       "      <td>2.838401887855639</td>\n",
       "      <td>4.627336419548448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>20</td>\n",
       "      <td>3.135649174690451</td>\n",
       "      <td>4.630370075497084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNNWithZScore</td>\n",
       "      <td>pearson</td>\n",
       "      <td>10</td>\n",
       "      <td>2.846543907781204</td>\n",
       "      <td>4.630564057985998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>40</td>\n",
       "      <td>3.2935301102100545</td>\n",
       "      <td>4.635830288447983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>cosine</td>\n",
       "      <td>10</td>\n",
       "      <td>2.915473568462295</td>\n",
       "      <td>4.636097184951954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>MSD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9726532346371601</td>\n",
       "      <td>4.636335001385556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KNNWithZScore</td>\n",
       "      <td>cosine</td>\n",
       "      <td>10</td>\n",
       "      <td>2.9293002712720866</td>\n",
       "      <td>4.638793602188325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KNNWithZScore</td>\n",
       "      <td>MSD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9746280465135104</td>\n",
       "      <td>4.649893476266271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>10</td>\n",
       "      <td>2.86491864228792</td>\n",
       "      <td>4.66639805357661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_type similarity_option   k          train_rmse  \\\n",
       "17   KNNWithMeans           pearson  40  3.2531799491999114   \n",
       "13   KNNWithMeans            cosine  20   3.159682964715261   \n",
       "14   KNNWithMeans            cosine  40  3.2903850378669244   \n",
       "16   KNNWithMeans           pearson  20  3.1003618713234586   \n",
       "10   KNNWithMeans               MSD  20  1.3359292867425185   \n",
       "11   KNNWithMeans               MSD  40  1.6799542931536193   \n",
       "23  KNNWithZScore            cosine  40   3.296224688519716   \n",
       "20  KNNWithZScore               MSD  40  1.6825021258480246   \n",
       "26  KNNWithZScore           pearson  40  3.2576625023139862   \n",
       "22  KNNWithZScore            cosine  20  3.1618570717831602   \n",
       "4        KNNBasic            cosine  20  3.1617757985124015   \n",
       "19  KNNWithZScore               MSD  20  1.3396796792224153   \n",
       "5        KNNBasic            cosine  40  3.3030329571595445   \n",
       "25  KNNWithZScore           pearson  20   3.106248847622633   \n",
       "2        KNNBasic               MSD  40  1.6936313947962665   \n",
       "1        KNNBasic               MSD  20  1.3413152744327146   \n",
       "9    KNNWithMeans               MSD  10   0.972312697133904   \n",
       "12   KNNWithMeans            cosine  10  2.9176009729694705   \n",
       "15   KNNWithMeans           pearson  10   2.838401887855639   \n",
       "7        KNNBasic           pearson  20   3.135649174690451   \n",
       "24  KNNWithZScore           pearson  10   2.846543907781204   \n",
       "8        KNNBasic           pearson  40  3.2935301102100545   \n",
       "3        KNNBasic            cosine  10   2.915473568462295   \n",
       "0        KNNBasic               MSD  10  0.9726532346371601   \n",
       "21  KNNWithZScore            cosine  10  2.9293002712720866   \n",
       "18  KNNWithZScore               MSD  10  0.9746280465135104   \n",
       "6        KNNBasic           pearson  10    2.86491864228792   \n",
       "\n",
       "             test_rmse  \n",
       "17   4.573265990871269  \n",
       "13  4.5799248468706075  \n",
       "14   4.583245241152444  \n",
       "16  4.5905238569670885  \n",
       "10  4.5925886023067655  \n",
       "11   4.595086217615626  \n",
       "23  4.5953194284848875  \n",
       "20  4.5994594505434705  \n",
       "26   4.600459390823622  \n",
       "22   4.601089923272977  \n",
       "4    4.604718491496385  \n",
       "19    4.60527867262265  \n",
       "5   4.6057789357366845  \n",
       "25  4.6070554199151355  \n",
       "2    4.616938317859895  \n",
       "1    4.618288844621761  \n",
       "9    4.618542054046472  \n",
       "12    4.62400255806853  \n",
       "15   4.627336419548448  \n",
       "7    4.630370075497084  \n",
       "24   4.630564057985998  \n",
       "8    4.635830288447983  \n",
       "3    4.636097184951954  \n",
       "0    4.636335001385556  \n",
       "21   4.638793602188325  \n",
       "18   4.649893476266271  \n",
       "6     4.66639805357661  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store result to dataframe and sort by test root mean square error by ascending order (smaller rmse = smaller error)\n",
    "df_kNN = pd.DataFrame(kNN_scores, columns = ['model_type', 'similarity_option', 'k', 'train_rmse', 'test_rmse'])\n",
    "df_kNN.sort_values(by = 'test_rmse', inplace = True)\n",
    "df_kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c517260a",
   "metadata": {},
   "source": [
    "Based on the results, best model seems to be this: \n",
    "- model type: `kNNWithMeans` \n",
    "- similarity option: `pearson` \n",
    "- `k`: 40\n",
    "<br>\n",
    "\n",
    "Overall, `pearson` seems to be a good similarity option. `kNNwithMeans` and `kNNWithZScore` outperforms `kNNBasic`.\n",
    "\n",
    "There is probably some overfitting, the train scores are much lower than the test scores (which is what you want, a low `rmse` score), but there is not much that can be done with it. The `cross_validated` test scores are quite promising. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11003950",
   "metadata": {},
   "source": [
    "### 4.1.2: Chosen Model Fitting for Memory Based Collaborative Filtering\n",
    "\n",
    "Rather than performing on k-fold (cross-validation), we will now train the data by using pre-split train & test data (real-world scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88e3f119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 4.5426\n",
      "4.5426344688433415\n"
     ]
    }
   ],
   "source": [
    "# based on above performance results\n",
    "chosen_k = 40\n",
    "chosen_sim_option = sim_pearson\n",
    "\n",
    "chosen_knn = KNNWithMeans(k = chosen_k, sim_options = chosen_sim_option)\n",
    "chosen_knn.fit(trainset)\n",
    "\n",
    "predictions_knn = chosen_knn.test(testset)\n",
    "accuracy_knn = accuracy.rmse(predictions_knn)\n",
    "print(accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa6d9d",
   "metadata": {},
   "source": [
    "`rmse` score for the chosen kNN without baseline model is __4.5426__. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd533e",
   "metadata": {},
   "source": [
    "## 4.2: Model-based models Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a5f85",
   "metadata": {},
   "source": [
    "### 4.2.1: `Matrix Factorization-based algorithms` - SVD (Singular value decomposition)\n",
    "\n",
    "First, we need to fine tune the hyperparameter by trial and error, the process can be made easier by utilizing GridSearchCV:\n",
    "- `n_factors` : The number of factors. Default is 100.\n",
    "- `n_epochs`  : The number of iteration of the SGD procedure. Default is 20.\n",
    "- `lr_all`    : The learning rate for all parameters. Default is 0.005.\n",
    "- `reg_all`   : The regularization term for all parameters. Default is 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0b8b6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  4.1min finished\n"
     ]
    }
   ],
   "source": [
    "# randomly set hyperparameter\n",
    "param_grid_1 = {'n_factors':[50, 100, 150], 'n_epochs': [10, 20, 30], \n",
    "                'lr_all': [0.002, 0.005, 0.008], 'reg_all': [0.01, 0.02, 0.03]}\n",
    "\n",
    "gs_model_1 = GridSearchCV(SVD, param_grid = param_grid_1, n_jobs = -1, joblib_verbose = 5)\n",
    "gs_model_1.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d5d1d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.466144549910821, 'mae': 3.361722795181818}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_1.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9b898e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 150, 'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.03},\n",
       " 'mae': {'n_factors': 100, 'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.03}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_1.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f257e",
   "metadata": {},
   "source": [
    "Intepretations & thoughts process\n",
    "- Since `n_factors` show better result at **higher** range `100`, we will try compare with `200`\n",
    "- Since `n_epochs` show better result at **lower** range `10`, we will try compare with `5`\n",
    "- Since `lr_all` show better result at **lower** range `0.002`, we will try compare with `0.001`\n",
    "- Since `reg_all` show better result at **higher** range `0.03`, we will try compare with `0.04 & 0.05`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1166e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 120 | elapsed:   44.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   44.7s finished\n"
     ]
    }
   ],
   "source": [
    "# set hyperparameter based on above best_params. to find 'better' parameter\n",
    "param_grid_2 = {'n_factors':[150, 200], 'n_epochs': [5, 10], \n",
    "                'lr_all': [0.001, 0.002], 'reg_all': [0.03, 0.04, 0.05]}\n",
    "\n",
    "gs_model_2 = GridSearchCV(SVD, param_grid = param_grid_2, n_jobs = -1, joblib_verbose = 5)\n",
    "gs_model_2.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbd9463d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.453403248090696, 'mae': 3.3533491795436654}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_2.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "789378e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 200, 'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.05},\n",
       " 'mae': {'n_factors': 200, 'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.05}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_2.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc09bb",
   "metadata": {},
   "source": [
    "Intepretations & thoughts process\n",
    "- Since `n_factors` show better result at **higher** range `200`, we will try compare with `300 & 400`\n",
    "- Since `n_epochs` doesn't show better result, we will stop tuning it and set as `10`\n",
    "- Since `lr_all` doesn't show better result, we will stop tuning it and set as `0.002`\n",
    "- Since `reg_all` show better result at **higher** range `0.05`, we will try compare with `0.10 & 0.15`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71ffd8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  45 | elapsed:   24.2s remaining:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  45 | elapsed:   42.0s remaining:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   43.1s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid_3 = {'n_factors':[200, 300, 400], 'n_epochs': [10], \n",
    "                'lr_all': [0.002], 'reg_all': [0.05, 0.10, 0.15]}\n",
    "\n",
    "gs_model_3 = GridSearchCV(SVD, param_grid = param_grid_3, n_jobs = -1, joblib_verbose = 5)\n",
    "gs_model_3.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "604a04ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.4343113079349195, 'mae': 3.340715639244651}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_3.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e90370fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 300, 'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.1},\n",
       " 'mae': {'n_factors': 300, 'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.1}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_3.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eecfd7a",
   "metadata": {},
   "source": [
    "Intepretations & thoughts process\n",
    "- Since `n_factors` show better result at **middle** range `300`, we will try compare with `250 & 350`\n",
    "- Since `n_epochs` doesn't show better result, we will stop tuning it and set as `10`\n",
    "- Since `lr_all` doesn't show better result, we will stop tuning it and set as `0.002`\n",
    "- Since `reg_all` show better result at **middle** range `0.1`, we will try compare with `0.08 & 0.12`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae67e407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  45 | elapsed:   24.1s remaining:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  45 | elapsed:   38.5s remaining:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   39.4s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid_4 = {'n_factors':[250, 300, 350], 'n_epochs': [10], \n",
    "                'lr_all': [0.002], 'reg_all': [0.08, 0.10, 0.12]}\n",
    "\n",
    "gs_model_4 = GridSearchCV(SVD, param_grid = param_grid_4, n_jobs = -1, joblib_verbose = 5)\n",
    "gs_model_4.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0271e609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.431495567615721, 'mae': 3.337983586097452}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_4.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e70a909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 300, 'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.1},\n",
       " 'mae': {'n_factors': 300, 'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.1}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_4.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef1894",
   "metadata": {},
   "source": [
    "Intepretations & thoughts process\n",
    "- Since `n_factors` doesn't show better result, we will stop tuning it and set as `300`\n",
    "- Since `n_epochs` doesn't show better result, we will stop tuning it and set as `10`\n",
    "- Since `lr_all` doesn't show better result, we will stop tuning it and set as `0.002`\n",
    "- Since `reg_all` doesn't show better result, we will stop tuning it and set as `0.1`\n",
    "\n",
    "We will stop exploring apply the hyperparameter on trainset & testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "799e541d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.4368\n",
      "4.436752521505912\n"
     ]
    }
   ],
   "source": [
    "chosen_SVD = SVD(n_factors= 300, n_epochs=10, lr_all=0.002, reg_all=0.1)\n",
    "chosen_SVD.fit(trainset)\n",
    "predictions_SVD = chosen_SVD.test(testset)\n",
    "accuracy_SVD = accuracy.rmse(predictions_SVD)\n",
    "print(accuracy_SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb719189",
   "metadata": {},
   "source": [
    "`rmse` score for the chosen SVD model is __4.4368__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785973f0",
   "metadata": {},
   "source": [
    "### 4.2.2: `Matrix Factorization-based algorithms` - SVD++\n",
    "\n",
    "The SVD++ algorithm, an extension of SVD taking into account implicit ratings. </br>\n",
    "\n",
    "First, we need to fine tune the hyperparameter by trial and error, the process can be made easier by utilizing GridSearchCV:\n",
    "- `n_factors` : The number of factors. Default is 20.\n",
    "- `n_epochs`  : The number of iteration of the SGD procedure. Default is 20.\n",
    "- `lr_all`    : The learning rate for all parameters. Default is 0.007\n",
    "- `reg_all`   : The regularization term for all parameters. Default is 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09243885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed: 23.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2465.3257999420166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 41.1min finished\n"
     ]
    }
   ],
   "source": [
    "## commented to avoid re-rerun (~41 minutes required)\n",
    "\n",
    "# param_grid_5 = {'n_factors':[10, 20, 30], 'n_epochs': [10, 20, 30], \n",
    "#                 'lr_all': [0.005, 0.007, 0.009], 'reg_all': [0.01, 0.02, 0.04]}\n",
    "\n",
    "# gs_model_5 = GridSearchCV(SVDpp, param_grid = param_grid_5, n_jobs = -1, joblib_verbose = 5)\n",
    "# gs_model_5.fit(data)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f38104bc",
   "metadata": {},
   "source": [
    "Result: \n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "* Note : Since it took 41minute to finish the process, might not be a good idea to rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10da6ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.6013136585104375, 'mae': 3.4057897377720465}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_5.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2fdb077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 10, 'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.04},\n",
       " 'mae': {'n_factors': 10, 'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.04}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_5.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17468ad8",
   "metadata": {},
   "source": [
    "Intepretations & thoughts process\n",
    "- Since `n_factors` show better result at **lower** range `10`, we will try compare with `5`\n",
    "- Since `n_epochs` show better result at **lower** range `10`, we will try compare with `5`\n",
    "- Since `lr_all` show better result at **lower** range `0.005`, we will try compare with `0.003 & 0.004`\n",
    "- Since `reg_all` show better result at **higher** range `0.04`, we will try compare with `0.05 & 0.06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbe8fa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  3.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.597898391882579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  5.6min finished\n"
     ]
    }
   ],
   "source": [
    "## uncomment to re-rerun (~5.6 minutes required)\n",
    "\n",
    "# param_grid_6 = {'n_factors':[5, 10], 'n_epochs': [5, 10], \n",
    "#                 'lr_all': [0.003, 0.004, 0.005], 'reg_all': [0.04, 0.05, 0.06]}\n",
    "\n",
    "# gs_model_6 = GridSearchCV(SVDpp, param_grid = param_grid_6, n_jobs = -1, joblib_verbose = 5)\n",
    "# gs_model_6.fit(data)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "69f191d9",
   "metadata": {},
   "source": [
    "Result:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d177ba8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.407410899254617, 'mae': 3.2950079420342036}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_6.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3382e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 10, 'n_epochs': 5, 'lr_all': 0.003, 'reg_all': 0.04},\n",
       " 'mae': {'n_factors': 10, 'n_epochs': 10, 'lr_all': 0.003, 'reg_all': 0.05}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_6.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a1aca",
   "metadata": {},
   "source": [
    "Intepretations & thoughts process\n",
    "- Since `n_factors` doesn't show better result {rmse}, we will stop tuning it and set as `10`\n",
    "- Since `n_epochs` show better result at **lower** range `5`, we will try compare with `3 & 4`\n",
    "- Since `lr_all` show better result at **lower** range `0.003`, we will try compare with `0.001 & 0.002`\n",
    "- Since `reg_all` doesn't show better result {rmse}, we will stop tuning it and set as `0.04`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07a7585f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  45 | elapsed:   33.4s remaining:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  45 | elapsed:   50.9s remaining:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   51.8s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid_7 = {'n_factors':[10], 'n_epochs': [3, 4, 5], \n",
    "                'lr_all': [0.001, 0.002, 0.003], 'reg_all': [0.04]}\n",
    "\n",
    "gs_model_7 = GridSearchCV(SVDpp, param_grid = param_grid_7, n_jobs = -1, joblib_verbose = 5)\n",
    "gs_model_7.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36d87d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.401016558669431, 'mae': 3.3200587466279474}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_7.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67eecf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 10, 'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.04},\n",
       " 'mae': {'n_factors': 10, 'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.04}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_7.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50ed1ae",
   "metadata": {},
   "source": [
    "Intepretations & thoughts process\n",
    "- Since `n_factors` doesn't show better result {rmse}, we will stop tuning it and set as `10`\n",
    "- Since `n_epochs` doesn't show better result {rmse}, we will stop tuning it and set as `5`\n",
    "- Since `lr_all` show better result at **middle** range `0.002`, we will set as `0.002`\n",
    "- Since `reg_all` doesn't show better result {rmse}, we will stop tuning it and set as `0.04`\n",
    "\n",
    "We will stop exploring apply the hyperparameter on trainset & testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7fd7639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.3962\n",
      "4.396212009543398\n"
     ]
    }
   ],
   "source": [
    "chosen_SVDpp = SVDpp(n_factors= 10, n_epochs=5, lr_all=0.002, reg_all=0.04)\n",
    "chosen_SVDpp.fit(trainset)\n",
    "predictions_SVDpp = chosen_SVDpp.test(testset)\n",
    "accuracy_SVDpp = accuracy.rmse(predictions_SVDpp)\n",
    "print(accuracy_SVDpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f4449",
   "metadata": {},
   "source": [
    "`rmse` score for the chosen SVDpp model is __4.3962__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4f2989",
   "metadata": {},
   "source": [
    "### 4.2.3: `Slope One`\n",
    "\n",
    "A simple yet accurate collaborative filtering algorithm.\n",
    "> No hyperparameter for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04908537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-a7ed0cc085d0>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  slopeone.fit(trainset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.5380\n"
     ]
    }
   ],
   "source": [
    "slopeone = SlopeOne()\n",
    "slopeone.fit(trainset)\n",
    "predictions_s1 = slopeone.test(testset)\n",
    "accuracy_s1 = accuracy.rmse(predictions_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8970ae",
   "metadata": {},
   "source": [
    "`rmse` score for the chosen SlopeOne model is __4.5380__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d44a07",
   "metadata": {},
   "source": [
    "### 4.2.4: `CoClustering`\n",
    "\n",
    "A collaborative filtering algorithm based on co-clustering.\n",
    "\n",
    "- `n_cltr_u` : Number of user clusters. Default is 3.\n",
    "- `n_cltr_i` :  Number of item clusters. Default is 3.\n",
    "- `n_epochs` : Number of iteration of the optimization loop. Default is 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "024d7ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 132 out of 135 | elapsed:   39.5s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:   39.9s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid_8 = {'n_cltr_u':[2, 3, 4], 'n_cltr_i': [2, 3, 4], 'n_epochs': [10, 20, 30]}\n",
    "\n",
    "gs_model_8 = GridSearchCV(CoClustering, param_grid = param_grid_8, n_jobs = -1, joblib_verbose = 5)\n",
    "gs_model_8.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c14a2a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.5920449729965425, 'mae': 3.4012237122189006}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_8.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5faedac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_cltr_u': 2, 'n_cltr_i': 3, 'n_epochs': 30},\n",
       " 'mae': {'n_cltr_u': 2, 'n_cltr_i': 3, 'n_epochs': 10}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_8.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78b179",
   "metadata": {},
   "source": [
    "Intepretations & thoughts process\n",
    "- Since `n_cltr_u` show better result at **lower** range `2`, we will try compare with `1`\n",
    "- Since `n_cltr_i` show better result at **middle** range `3`, we will set as `3`\n",
    "- Since `n_epochs` show better result at **higher** range `30`, we will try compare with `40 & 50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8db5d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  30 | elapsed:    6.5s remaining:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  30 | elapsed:    9.0s remaining:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  30 | elapsed:   10.1s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:   13.6s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   14.3s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid_9 = {'n_cltr_u':[1, 2], 'n_cltr_i': [3], 'n_epochs': [30, 40, 50]}\n",
    "\n",
    "gs_model_9 = GridSearchCV(CoClustering, param_grid = param_grid_9, n_jobs = -1, joblib_verbose = 5)\n",
    "gs_model_9.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24e3dabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.567399848705735, 'mae': 3.3907040873678262}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_9.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4e109ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_cltr_u': 1, 'n_cltr_i': 3, 'n_epochs': 30},\n",
       " 'mae': {'n_cltr_u': 1, 'n_cltr_i': 3, 'n_epochs': 30}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model_9.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d30fdc9",
   "metadata": {},
   "source": [
    "Intepretations & thoughts process\n",
    "- Since `n_cltr_u` show better result at **lowest** range `1`, we will set as `1`\n",
    "- Since `n_cltr_i` doesn't show better result {rmse}, we will stop tuning it and set as `3`\n",
    "- Since `n_epochs` doesn't show better result {rmse}, we will stop tuning it and set as `30`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "14b7cf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-13b0258b4f57>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  coclustering.fit(trainset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.5731\n"
     ]
    }
   ],
   "source": [
    "coclustering = CoClustering(n_cltr_u = 1, n_cltr_i = 3, n_epochs = 30)\n",
    "coclustering.fit(trainset)\n",
    "predictions_cocl = coclustering.test(testset)\n",
    "accuracy_cocl = accuracy.rmse(predictions_cocl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764cd83",
   "metadata": {},
   "source": [
    "`rmse` score for the chosen CoClustering model is __4.5731__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03dcd53",
   "metadata": {},
   "source": [
    "# Part 5: Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb187e21",
   "metadata": {},
   "source": [
    "## 5.1: Model Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f06e5cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Fraction of Concordant Pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model-based</td>\n",
       "      <td>SVD++</td>\n",
       "      <td>4.396212</td>\n",
       "      <td>19.326680</td>\n",
       "      <td>3.298829</td>\n",
       "      <td>0.562282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model-based</td>\n",
       "      <td>SVD</td>\n",
       "      <td>4.436753</td>\n",
       "      <td>19.684773</td>\n",
       "      <td>3.347508</td>\n",
       "      <td>0.578480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model-based</td>\n",
       "      <td>SlopeOne</td>\n",
       "      <td>4.537959</td>\n",
       "      <td>20.593073</td>\n",
       "      <td>3.361475</td>\n",
       "      <td>0.562952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Memory-based</td>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>4.542634</td>\n",
       "      <td>20.635528</td>\n",
       "      <td>3.359994</td>\n",
       "      <td>0.579800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model-based</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>4.573117</td>\n",
       "      <td>20.913403</td>\n",
       "      <td>3.395089</td>\n",
       "      <td>0.569040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Type    Model Name  Root Mean Squared Error  Mean Squared Error  \\\n",
       "2   Model-based         SVD++                 4.396212           19.326680   \n",
       "1   Model-based           SVD                 4.436753           19.684773   \n",
       "3   Model-based      SlopeOne                 4.537959           20.593073   \n",
       "0  Memory-based  KNNWithMeans                 4.542634           20.635528   \n",
       "4   Model-based  CoClustering                 4.573117           20.913403   \n",
       "\n",
       "   Mean Absolute Error  Fraction of Concordant Pairs  \n",
       "2             3.298829                      0.562282  \n",
       "1             3.347508                      0.578480  \n",
       "3             3.361475                      0.562952  \n",
       "0             3.359994                      0.579800  \n",
       "4             3.395089                      0.569040  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives model report in dataframe\n",
    "def model_report(model_type, model_name, predictions) :\n",
    "\n",
    "    rmse = accuracy.rmse(predictions,verbose = False)\n",
    "    mse  = accuracy.mse(predictions, verbose = False)\n",
    "    mae  = accuracy.mae(predictions, verbose = False)\n",
    "    fcp  = accuracy.fcp(predictions, verbose = False)\n",
    " \n",
    "    df = pd.DataFrame({\"Model Type\"                  : [model_type],\n",
    "                       \"Model Name\"                  : [model_name],\n",
    "                       \"Root Mean Squared Error\"     : [rmse],\n",
    "                       \"Mean Squared Error\"          : [mse],\n",
    "                       \"Mean Absolute Error\"         : [mae],\n",
    "                       \"Fraction of Concordant Pairs\": [fcp],\n",
    "                      })\n",
    "    return df\n",
    "\n",
    "report_knn   = model_report('Memory-based', 'KNNWithMeans', predictions_knn)\n",
    "report_SVD   = model_report('Model-based' , 'SVD', predictions_SVD)\n",
    "report_SVDpp = model_report('Model-based' , 'SVD++', predictions_SVDpp)\n",
    "report_s1    = model_report('Model-based' , 'SlopeOne', predictions_s1)\n",
    "report_cocl  = model_report('Model-based' , 'CoClustering', predictions_cocl)\n",
    "\n",
    "#concat all models\n",
    "model_performances = pd.concat([report_knn,report_SVD,report_SVDpp,report_s1,report_cocl], axis = 0).reset_index()\n",
    "\n",
    "model_performances = model_performances.drop(columns = \"index\", axis =1)\n",
    "\n",
    "model_performances.sort_values(by = 'Root Mean Squared Error', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14db248",
   "metadata": {},
   "source": [
    "As we can observed from above, `SVD++` has the lowest Root Mean Squared Error compared to the rest, </br>\n",
    "However it also has the lowest `FCP` (Higher is better).\n",
    "\n",
    "Also due to the facts that `SVD++` takes extremely large time to build the model compare to the 2nd Lowest `RSME` which is `SVD` </br>\n",
    "Not to mentioned that `SVD` also has the 2nd highest `FCP` across all models\n",
    "\n",
    "For this Jester Recommendation Engine, we can conclude \n",
    "\n",
    "* For Lowest RMSE --> `SVD++`\n",
    "* For Highest FCP --> `KNNWithMeans`\n",
    "* For Overall Performance --> `SVD `\n",
    "\n",
    "Fraction of Concordant Pairs (FCP)\n",
    "> If product A receives a higher rating than product B from a user and the model predicts the same, A and B are a concordant pair, otherwise a discordant pair. FCP is simply the fraction of concordant pairs among all the pairs (sum over all users)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99421303",
   "metadata": {},
   "source": [
    "# Part 6: Recommendation Engine\n",
    "\n",
    "Get the k nearest neighbors of an item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "314d0462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "\n",
      "\n",
      "input_jokes:  Q: How do you keep a computer programmer in the  shower all day long?  A: Give them a shampoo with a label that says \"rinse, lather, repeat\".\n",
      "\n",
      "\n",
      "\n",
      "The 10 nearest neighbors of input_jokes are:\n",
      "1:  What is the rallying cry of the International Dyslexic Pride movement? Dyslexics Untie!\n",
      "\n",
      "2:  A couple has been married for 75 years. For the husband's 95th birthday, his wife decides to surprise him by hiring a prostitute. That day, the doorbell rings. The husband uses his walker to get to the door and opens it.  A 21-year-old in a latex outfit smiles and says, \"Hi, I here to give you super sex!\"  The old man says, \"I'll take the soup.\"\n",
      "\n",
      "3:  What do you call an American in the finals of the world cup?  \"Hey Beer Man!\"\n",
      "\n",
      "4:  An artist asked the gallery owner if there had been any interest in his paintings currently on display. \"I've got good news and bad news,\" the owner replied. \"The good news is that a gentleman inquired about your work and wondered if it would appreciate in value after your death. When I told him it would, he bought all fifteen of your paintings.\" \"That's wonderful!\" the artist exclaimed. \"What's the bad news?\" With concern, the gallery owner replied: \"The guy was your doctor.\"\n",
      "\n",
      "5:  The new employee stood before the paper shredder looking confused. \"Need some help?\" a secretary, walking by, asked. \"Yes,\" he replied, \"how does this thing work?\" \"Simple,\" she said, taking the fat report from his hand and feeding it into the shredder.\"Thanks, but where do the copies come out?\"\n",
      "\n",
      "6:  How many teddybears does it take to change a lightbulb?  It takes only one teddybear, but it takes a whole lot of lightbulbs.\n",
      "\n",
      "7:  An engineer, a physicist and a mathematician are sleeping in a room. There is a fire in the room. The engineer wakes up, sees the fire, picks up the bucket of water and douses the fire and goes back to sleep.   Again there is fire in the room. This time, the physicist wakes up, notices the bucket, fills it with water, calculates the optimal trajectory and douses the fire in minimum amount of water and goes back to sleep.   Again there is fire. This time the mathematician wakes up.  He looks at the fire, looks at the bucket and the water and exclaims, \"A solution exists\" and goes back to sleep.\n",
      "\n",
      "8:  Employer to applicant: \"In this job we need someone who is responsible.\"  Applicant: \"I'm the one you want. On my last job, every time anything went wrong, they said I was responsible.\"\n",
      "\n",
      "9:  \"Do you believe in life after death?\" the boss asked one of his employees.\"Yes, sir,\" the new recruit replied. \"Well, then, that makes everything just fine...\" the boss went on. \"After you left early yesterday to go to your grandmother's funeral, she stopped in to see you.\"\n",
      "\n",
      "10:  A neutron walks into a bar and orders a drink. \"How much do I owe you?\" the neutron asks.  The bartender replies, \"for you, no charge.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_jokes = 'jokes_82'\n",
    "\n",
    "# Read the mappings raw id <-> jokes name\n",
    "name_to_rid = {}\n",
    "rid_to_name = {}\n",
    "\n",
    "for i in trainsetfull_raw_iids:\n",
    "    name_to_rid[i] = trainsetfull_iids[trainsetfull_raw_iids.index(i)]\n",
    "    \n",
    "for i in trainsetfull_iids:\n",
    "    rid_to_name[i] = trainsetfull_raw_iids[trainsetfull_iids.index(i)]\n",
    "    \n",
    "# based on above performance results\n",
    "chosen_k = 40\n",
    "chosen_sim_option = sim_pearson\n",
    "\n",
    "# First, train the algortihm to compute the similarities between items\n",
    "algo = KNNWithMeans(k = chosen_k, sim_options = chosen_sim_option)\n",
    "algo.fit(trainsetfull)\n",
    "\n",
    "# Retrieve inner id of jokes_82\n",
    "input_jokes_raw_id = name_to_rid[input_jokes]\n",
    "\n",
    "# Retrieve the nearest neighbors of jokes_82 using inner id.\n",
    "input_jokes_neighbors = algo.get_neighbors(input_jokes_raw_id, k=10)\n",
    "\n",
    "# Convert inner ids of the neighbors into names.\n",
    "input_jokes_neighbors = (algo.trainset.to_raw_iid(inner_id) for inner_id in input_jokes_neighbors)\n",
    "\n",
    "print('\\n\\n')\n",
    "print('input_jokes:  ' + df_jokes.loc[input_jokes][0])\n",
    "print('\\n\\n')\n",
    "\n",
    "print('The 10 nearest neighbors of input_jokes are:')\n",
    "for count, jokes in enumerate(input_jokes_neighbors):\n",
    "    print( str(count+1) + ':  '     + df_jokes.loc[jokes][0] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0ac06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
